"""
Text –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π
–°–û–î–ï–†–ñ–ò–¢ –í–°–Æ –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–£–Æ –õ–û–ì–ò–ö–£ –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô!

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ç–æ–¥—ã –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π:
- get_response() - –æ–±—ã—á–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
- get_response_streaming() - streaming –∑–∞–ø—Ä–æ—Å—ã
- get_response_without_system() - –∑–∞–ø—Ä–æ—Å—ã –±–µ–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
- general_medical_consultation() - –æ–±—â–∏–µ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏
- analyze_ecg_data() - –∞–Ω–∞–ª–∏–∑ –≠–ö–ì –¥–∞–Ω–Ω—ã—Ö
"""

import time
import requests
import json
from typing import Optional, Generator

from .base_client import BaseAPIClient
from .diagnostic_prompts import get_system_prompt
from .logging_handler import log_api_error, log_api_success, _get_model_name
from utils.error_handler import handle_error, log_api_call
from utils.performance_monitor import track_model_usage


class TextClient(BaseAPIClient):
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π
    
    –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –í—Å—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –ª–æ–≥–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π!
    –í—Å–µ –º–µ—Ç–æ–¥—ã —è–≤–ª—è—é—Ç—Å—è –¢–û–ß–ù–û–ô –ö–û–ü–ò–ï–ô –∏–∑ claude_assistant.py
    """
    
    def __init__(self, api_key: str, base_url: str = "https://openrouter.ai/api/v1/chat/completions"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Text –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            api_key: API –∫–ª—é—á OpenRouter
            base_url: –ë–∞–∑–æ–≤—ã–π URL API
        """
        super().__init__(api_key, base_url)
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞ - –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û!
        self.system_prompt = get_system_prompt()
        
        # –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏: Claude 4.5 —Å–µ—Ä–∏—è + Llama
        self.models = [
            "anthropic/claude-opus-4.5",
            "anthropic/claude-sonnet-4.5",
            "anthropic/claude-haiku-4.5",
            "meta-llama/llama-3.2-90b-vision-instruct"
        ]
        
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º Opus
        self.model = self.models[0]
    
    def get_response(
        self,
        user_message: str,
        context: str = "",
        use_sonnet_4_5: bool = False
    ) -> str:
        """
        –¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ª—É—á—à–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏
        
        –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –ª–æ–≥–∏–∫–∏ –∏–∑ claude_assistant.py (—Å—Ç—Ä–æ–∫–∏ 1829-1900)
        
        Args:
            user_message: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            use_sonnet_4_5: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Sonnet 4.5 (–¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤)
        
        Returns:
            str: –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
        """
        full_message = f"{context}\n\n–í–æ–ø—Ä–æ—Å: {user_message}" if context else user_message
        
        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–∞ –º–æ–¥–µ–ª—å Sonnet 4.5 –¥–ª—è –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, —Å—Ç–∞–≤–∏–º –µ—ë –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        if use_sonnet_4_5:
            models_to_try = ["anthropic/claude-sonnet-4.5"] + [m for m in self.models if m != "anthropic/claude-sonnet-4.5"]
        else:
            models_to_try = self.models
        
        # –ü—Ä–æ–±—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É
        for model in models_to_try:
            try:
                start_time = time.time()
                model_name = _get_model_name(model)
                print(f"ü§ñ [{model_name}] –ù–∞—á–∏–Ω–∞—é —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...")
                
                payload = {
                    "model": model,
                    "messages": [
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": full_message}
                    ],
                    "max_tokens": 8000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
                    "temperature": 0.2
                }
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                prompt_size = len(full_message)
                if prompt_size > 50000:
                    print(f"‚ö†Ô∏è [{model_name}] –ë–æ–ª—å—à–æ–π –ø—Ä–æ–º–ø—Ç: {prompt_size} —Å–∏–º–≤–æ–ª–æ–≤. –ú–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏.")
                
                print(f"üì° [{model_name}] –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ API...")
                response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=300)
                latency = time.time() - start_time
                
                if response.status_code == 200:
                    result_data = response.json()
                    result = result_data["choices"][0]["message"]["content"]

                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
                    tokens_used = result_data.get("usage", {}).get("total_tokens", 0)
                    log_api_call(model, True, latency, None)
                    track_model_usage(model, True, tokens_used)

                    self.model = model
                    print(f"‚úÖ [{model_name}] –ó–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {latency:.2f}—Å, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used}")
                    return result
                elif response.status_code == 402:
                    # –û—à–∏–±–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –∫—Ä–µ–¥–∏—Ç–æ–≤
                    error_msg = f"HTTP 402: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ –Ω–∞ OpenRouter –¥–ª—è –º–æ–¥–µ–ª–∏ {model}"
                    log_api_call(model, False, latency, error_msg)
                    track_model_usage(model, False)
                    print(f"‚ö†Ô∏è {error_msg}. –ü—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å...")
                    continue
                else:
                    error_msg = f"HTTP {response.status_code}"
                    log_api_error(model, latency, error_msg)
                    continue
                    
            except requests.exceptions.Timeout:
                latency = time.time() - start_time if 'start_time' in locals() else 300
                error_msg = f"–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (>{300} —Å–µ–∫—É–Ω–¥)"
                log_api_error(model, latency, error_msg)
                continue
            except Exception as e:
                latency = time.time() - start_time if 'start_time' in locals() else 0
                error_msg = handle_error(e, f"get_response ({model})", show_to_user=False)
                log_api_call(model, False, latency, error_msg)
                track_model_usage(model, False)
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {model}: {e}")
                continue
        
        return "‚ùå –û—à–∏–±–∫–∞: –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ API –∫–ª—é—á–∏."
    
    def get_response_streaming(
        self,
        user_message: str,
        context: str = "",
        use_sonnet_4_5: bool = False,
        force_opus: bool = False
    ) -> Generator[str, None, None]:
        """
        –¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å streaming - —Ç–µ–∫—Å—Ç –ø–æ—è–≤–ª—è–µ—Ç—Å—è –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ
        
        –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –ª–æ–≥–∏–∫–∏ –∏–∑ claude_assistant.py (—Å—Ç—Ä–æ–∫–∏ 1902-2038)
        
        Args:
            user_message: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            use_sonnet_4_5: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Sonnet 4.5 (–¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤)
            force_opus: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Opus 4.5
        
        Yields:
            str: –ß–∞—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ –ø–æ –º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        full_message = f"{context}\n\n–í–æ–ø—Ä–æ—Å: {user_message}" if context else user_message
        
        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π Opus, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ–≥–æ
        if force_opus:
            models_to_try = ["anthropic/claude-opus-4.5"]
        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–∞ –º–æ–¥–µ–ª—å Sonnet 4.5, —Å—Ç–∞–≤–∏–º –µ—ë –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        elif use_sonnet_4_5:
            models_to_try = ["anthropic/claude-sonnet-4.5"] + [m for m in self.models if m != "anthropic/claude-sonnet-4.5"]
        else:
            models_to_try = self.models
        
        # –ü—Ä–æ–±—É–µ–º –º–æ–¥–µ–ª–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É
        start_time = time.time()
        for model in models_to_try:
            try:
                model_name = _get_model_name(model)
                model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                force_msg = " [FORCE_OPUS]" if force_opus else ""
                print(f"ü§ñ [{model_type}]{force_msg} [STREAMING] –ù–∞—á–∏–Ω–∞—é streaming —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –º–æ–¥–µ–ª–∏: {model_name}...")
                
                payload = {
                    "model": model,
                    "messages": [
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": full_message}
                    ],
                    "max_tokens": 8000,
                    "temperature": 0.2,
                    "stream": True
                }
                
                force_msg = " [FORCE_OPUS]" if force_opus else ""
                print(f"üì° [{model_type}]{force_msg} [STREAMING] –û—Ç–ø—Ä–∞–≤–ª—è—é streaming –∑–∞–ø—Ä–æ—Å –∫ API –¥–ª—è –º–æ–¥–µ–ª–∏: {model_name}...")
                response = requests.post(
                    self.base_url,
                    headers=self.headers,
                    json=payload,
                    timeout=180,
                    stream=True
                )
                
                if response.status_code == 200:
                    self.model = model
                    force_msg = " [FORCE_OPUS]" if force_opus else ""
                    print(f"‚úÖ [{model_type}]{force_msg} [STREAMING] Streaming –Ω–∞—á–∞—Ç –¥–ª—è –º–æ–¥–µ–ª–∏: {model_name}, –ø–æ–ª—É—á–∞—é –æ—Ç–≤–µ—Ç...")
                    tokens_received = 0
                    # –ß–∏—Ç–∞–µ–º stream
                    for line in response.iter_lines():
                        if line:
                            line_text = line.decode('utf-8')
                            if line_text.startswith('data: '):
                                data_str = line_text[6:]
                                if data_str.strip() == '[DONE]':
                                    latency = time.time() - start_time
                                    model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                                    force_msg = " [FORCE_OPUS]" if force_opus else ""
                                    context_msg = f"STREAMING ({model_name})" + (force_msg if force_opus else "")
                                    print(f"‚úÖ [{model_type}]{force_msg} [STREAMING] –ú–æ–¥–µ–ª—å: {model_name}, –¢–æ–∫–µ–Ω–æ–≤: {tokens_received}, Latency: {latency:.2f}—Å")
                                    log_api_success(model, latency, tokens_received, context_msg)
                                    break
                                try:
                                    data = json.loads(data_str)
                                    if 'choices' in data and len(data['choices']) > 0:
                                        delta = data['choices'][0].get('delta', {})
                                        content = delta.get('content', '')
                                        if content:
                                            tokens_received += len(content.split())
                                            yield content
                                        
                                        if 'usage' in data:
                                            tokens_used = data['usage'].get('total_tokens', 0)
                                            if tokens_used > 0:
                                                tokens_received = tokens_used
                                except json.JSONDecodeError:
                                    continue
                    return
                elif response.status_code == 402:
                    latency = time.time() - start_time if 'start_time' in locals() else 0
                    error_msg = f"HTTP 402: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ –Ω–∞ OpenRouter –¥–ª—è –º–æ–¥–µ–ª–∏ {model}"
                    log_api_call(model, False, latency, error_msg)
                    track_model_usage(model, False)
                    model_name = _get_model_name(model)
                    model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                    force_msg = " [FORCE_OPUS]" if force_opus else ""
                    print(f"‚ùå [{model_type}]{force_msg} [STREAMING] –ú–æ–¥–µ–ª—å: {model_name}, {error_msg}, Latency: {latency:.2f}—Å")
                    if force_opus:
                        yield f"\n‚ùå **–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ –Ω–∞ OpenRouter –¥–ª—è Opus 4.5**\n\n"
                        yield f"üí° –ü–æ–ø–æ–ª–Ω–∏—Ç–µ –±–∞–ª–∞–Ω—Å –Ω–∞ https://openrouter.ai/credits\n\n"
                        return
                    if model == "anthropic/claude-sonnet-4.5":
                        yield f"\n‚ö†Ô∏è **Sonnet 4.5 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤). –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å...**\n\n"
                    else:
                        yield f"\n‚ö†Ô∏è **{model_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤). –ü—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å...**\n\n"
                    continue
                elif response.status_code == 403:
                    latency = time.time() - start_time if 'start_time' in locals() else 0
                    error_text = response.text
                    model_name = _get_model_name(model)
                    model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                    force_msg = " [FORCE_OPUS]" if force_opus else ""
                    if "Key limit exceeded" in error_text or "limit" in error_text.lower():
                        error_msg = f"HTTP 403: –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç API –∫–ª—é—á–∞ OpenRouter –¥–ª—è –º–æ–¥–µ–ª–∏ {model}"
                        user_msg = f"‚ùå **–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç API –∫–ª—é—á–∞ OpenRouter**\n\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–∏–º–∏—Ç—ã –Ω–∞ https://openrouter.ai/settings/keys"
                    else:
                        error_msg = f"HTTP 403: {error_text[:200]}"
                        user_msg = f"‚ùå **–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ (HTTP 403)**\n\n{error_text[:200]}"
                    log_api_error(model, latency, error_msg, f"STREAMING{force_msg}")
                    print(f"‚ùå [{model_type}]{force_msg} [STREAMING] –ú–æ–¥–µ–ª—å: {model_name}, {error_msg}, Latency: {latency:.2f}—Å")
                    if force_opus:
                        yield f"\n{user_msg}\n\n"
                        return
                    yield f"\n{user_msg}\n–ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å...\n\n"
                    continue
                else:
                    latency = time.time() - start_time if 'start_time' in locals() else 0
                    error_msg = f"HTTP {response.status_code}: {response.text[:200]}"
                    model_name = _get_model_name(model)
                    model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                    force_msg = " [FORCE_OPUS]" if force_opus else ""
                    log_api_error(model, latency, error_msg, f"STREAMING{force_msg}")
                    print(f"‚ùå [{model_type}]{force_msg} [STREAMING] –ú–æ–¥–µ–ª—å: {model_name}, –û—à–∏–±–∫–∞: {error_msg}, Latency: {latency:.2f}—Å")
                    if force_opus:
                        yield f"‚ùå –û—à–∏–±–∫–∞: {error_msg}"
                        return
                    continue
                    
            except requests.exceptions.Timeout:
                latency = time.time() - start_time if 'start_time' in locals() else 300
                error_msg = f"–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (>{180} —Å–µ–∫—É–Ω–¥)"
                log_api_error(model, latency, error_msg)
                if force_opus:
                    yield f"‚ùå –û—à–∏–±–∫–∞: {error_msg}"
                    return
                continue
            except (requests.exceptions.ConnectionError, requests.exceptions.ChunkedEncodingError) as e:
                latency = time.time() - start_time if 'start_time' in locals() else 0
                error_msg = f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {str(e)}"
                log_api_error(model, latency, error_msg)
                model_name = _get_model_name(model)
                model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                force_msg = " [FORCE_OPUS]" if force_opus else ""
                print(f"‚ùå [{model_type}]{force_msg} [STREAMING] –ú–æ–¥–µ–ª—å: {model_name}, {error_msg}, Latency: {latency:.2f}—Å")
                if force_opus:
                    yield f"‚ö†Ô∏è **–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–∏ streaming**\n\n–°–µ—Ä–≤–µ—Ä –∑–∞–∫—Ä—ã–ª —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å.\n\n"
                    return
                yield f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name}. –ü—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é...\n\n"
                continue
            except Exception as e:
                latency = time.time() - start_time if 'start_time' in locals() else 0
                error_str = str(e)
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–æ–π —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                if 'Connection aborted' in error_str or 'Remote end closed' in error_str or 'RemoteDisconnected' in error_str:
                    error_msg = f"–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ —Å–µ—Ä–≤–µ—Ä–æ–º: {error_str}"
                    log_api_error(model, latency, error_msg)
                    model_name = _get_model_name(model)
                    model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                    force_msg = " [FORCE_OPUS]" if force_opus else ""
                    print(f"‚ùå [{model_type}]{force_msg} [STREAMING] –ú–æ–¥–µ–ª—å: {model_name}, {error_msg}, Latency: {latency:.2f}—Å")
                    if force_opus:
                        yield f"‚ö†Ô∏è **–°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ —Å–µ—Ä–≤–µ—Ä–æ–º**\n\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.\n\n"
                        return
                    yield f"‚ö†Ô∏è –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name}. –ü—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é...\n\n"
                else:
                    error_msg = handle_error(e, "get_response_streaming", show_to_user=False)
                    log_api_error(model, latency, error_msg)
                    if force_opus:
                        yield f"‚ùå –û—à–∏–±–∫–∞: {error_msg}"
                        return
                continue
        
        yield "‚ùå –û—à–∏–±–∫–∞: –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è streaming. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ API –∫–ª—é—á–∏."
    
    def general_medical_consultation(self, user_question: str) -> str:
        """
        –û–±—â–∞—è –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è
        
        –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py (—Å—Ç—Ä–æ–∫–∞ 2404)
        
        Args:
            user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Returns:
            str: –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
        """
        return self.get_response(user_question)
    
    def get_response_without_system(self, user_message: str, force_opus: bool = False) -> str:
        """
        –¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ë–ï–ó –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        
        –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py (—Å—Ç—Ä–æ–∫–∏ 2040-2113)
        
        Args:
            user_message: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–Ω—É—Ç—Ä–∏)
            force_opus: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Opus 4.5
        
        Returns:
            str: –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
        """
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç Opus –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
        if force_opus:
            models_to_try = ["anthropic/claude-opus-4.5"] + [
                m for m in self.models if m != "anthropic/claude-opus-4.5"
            ]
        else:
            models_to_try = self.models

        for model in models_to_try:
            try:
                start_time = time.time()
                model_name = _get_model_name(model)
                print(f"ü§ñ [{model_name} NO SYSTEM] –ù–∞—á–∏–Ω–∞—é —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –±–µ–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞...")
                
                payload = {
                    "model": model,
                    "messages": [
                        {"role": "user", "content": user_message}
                    ],
                    "max_tokens": 8000,
                    "temperature": 0.2,
                }

                timeout_value = 180 if 'opus' in model.lower() else 120
                print(f"üì° [{model_name} NO SYSTEM] –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ API...")
                response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=timeout_value)
                latency = time.time() - start_time

                if response.status_code == 200:
                    result_data = response.json()
                    result = result_data["choices"][0]["message"]["content"]

                    tokens_used = result_data.get("usage", {}).get("total_tokens", 0)
                    model_type = "üß† OPUS" if "opus" in model.lower() else "ü§ñ SONNET" if "sonnet" in model.lower() else "‚ö° FLASH" if "gemini" in model.lower() or "flash" in model.lower() else "‚ùì UNKNOWN"
                    print(f"‚úÖ [{model_type}] [NO SYSTEM] –ú–æ–¥–µ–ª—å: {model_name}, –¢–æ–∫–µ–Ω–æ–≤: {tokens_used}, Latency: {latency:.2f}—Å")
                    log_api_call(model, True, latency, None)
                    track_model_usage(model, True, tokens_used)

                    self.model = model
                    return result
                elif response.status_code == 402:
                    error_msg = f"HTTP 402: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ –Ω–∞ OpenRouter –¥–ª—è –º–æ–¥–µ–ª–∏ {model}"
                    log_api_call(model, False, latency, error_msg)
                    track_model_usage(model, False)
                    print(f"‚ùå [{model_name} NO SYSTEM] {error_msg}. –ü—Ä–æ–±—É—é —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å...")
                    continue
                else:
                    error_msg = f"HTTP {response.status_code}"
                    log_api_error(model, latency, error_msg)
                    continue

            except requests.exceptions.Timeout:
                latency = time.time() - start_time if 'start_time' in locals() else 0
                error_msg = "–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (>300 —Å–µ–∫—É–Ω–¥)"
                log_api_call(model, False, latency, error_msg)
                track_model_usage(model, False)
                print(f"‚ö†Ô∏è –¢–∞–π–º–∞—É—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ {model}")
                continue
            except Exception as e:
                latency = time.time() - start_time if 'start_time' in locals() else 0
                error_msg = handle_error(e, f"get_response_without_system ({model})", show_to_user=False)
                log_api_call(model, False, latency, error_msg)
                track_model_usage(model, False)
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {model}: {e}")
                continue

        return "‚ùå –û—à–∏–±–∫–∞: –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –±–µ–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞."
    
    def analyze_ecg_data(self, ecg_analysis: dict, user_question: str = None) -> str:
        """
        –ê–Ω–∞–ª–∏–∑ –≠–ö–ì –¥–∞–Ω–Ω—ã—Ö —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        
        –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py (—Å—Ç—Ä–æ–∫–∏ 2408-2427)
        
        Args:
            ecg_analysis: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –≠–ö–ì
            user_question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
        Returns:
            str: –û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏
        """
        context = f"""
üìä –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó –≠–ö–ì:
‚Ä¢ –ß–∞—Å—Ç–æ—Ç–∞ —Å–µ—Ä–¥–µ—á–Ω—ã—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π: {ecg_analysis.get('heart_rate', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')} —É–¥/–º–∏–Ω
‚Ä¢ –†–∏—Ç–º: {ecg_analysis.get('rhythm_assessment', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω')}
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ QRS –∫–æ–º–ø–ª–µ–∫—Å–æ–≤: {ecg_analysis.get('num_beats', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}
‚Ä¢ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏: {ecg_analysis.get('duration', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞')} —Å
‚Ä¢ –ö–∞—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–∞: {ecg_analysis.get('signal_quality', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')}
"""
        
        question = user_question or """
–ö–∞–∫ –≤—Ä–∞—á-–∫–∞—Ä–¥–∏–æ–ª–æ–≥, –ø—Ä–æ–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π—Ç–µ —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –≠–ö–ì:
1. –û—Ü–µ–Ω–∏—Ç–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ä–∏—Ç–º–∞ –∏ –ø—Ä–æ–≤–æ–¥–∏–º–æ—Å—Ç–∏
2. –í—ã—è–≤–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
3. –ü—Ä–µ–¥–ª–æ–∂–∏—Ç–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
4. –î–∞–π—Ç–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–ª—å–Ω–µ–π—à–µ–º—É –≤–µ–¥–µ–Ω–∏—é
"""
        return self.get_response(question, context)

