"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è - —Ç–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å
–ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–æ–π –ª–æ–≥–∏–∫–∏!

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è API –∑–∞–ø—Ä–æ—Å–æ–≤.
–í—Å—è –ª–æ–≥–∏–∫–∞ —è–≤–ª—è–µ—Ç—Å—è –¢–û–ß–ù–û–ô –ö–û–ü–ò–ï–ô –∏–∑ claude_assistant.py –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
"""

import logging
from utils.error_handler import log_api_call
from utils.performance_monitor import track_model_usage

logger = logging.getLogger(__name__)


def _get_model_name(model: str) -> str:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —á–∏—Ç–∞–µ–º–æ–≥–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏ - –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py
    
    Args:
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ API
    
    Returns:
        str: –ß–∏—Ç–∞–µ–º–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏
    """
    # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py (–º–µ—Ç–æ–¥ _get_model_name)
    model_mapping = {
        "anthropic/claude-opus-4.5": "Claude Opus 4.5",
        "anthropic/claude-sonnet-4.5": "Claude Sonnet 4.5",
        "anthropic/claude-haiku-4.5": "Claude Haiku 4.5",
        "meta-llama/llama-3.2-90b-vision-instruct": "Llama 3.2 90B Vision"
    }
    return model_mapping.get(model, model)


def _get_model_type(model: str) -> str:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è - –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py
    
    Args:
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ API
    
    Returns:
        str: –¢–∏–ø –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ª–æ–≥–∞—Ö
    """
    # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py —Å—Ç—Ä–æ–∫–∏ 199, 216
    if "gemini" in model.lower() or "flash" in model.lower():
        return "‚ö° FLASH"
    elif "opus" in model.lower():
        return "üß† OPUS"
    elif "sonnet" in model.lower():
        return "ü§ñ SONNET"
    else:
        return "‚ùì UNKNOWN"


def log_api_error(model: str, latency: float, error_msg: str, context: str = ""):
    """
    –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–∫–∏ API –≤—ã–∑–æ–≤–∞ - –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py
    
    Args:
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        latency: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        error_msg: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ –º–µ—Ç–æ–¥—É _log_api_error –∏–∑ claude_assistant.py (—Å—Ç—Ä–æ–∫–∏ 187-203)
    """
    # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py —Å—Ç—Ä–æ–∫–∏ 196-203
    log_api_call(model, False, latency, error_msg)
    track_model_usage(model, False)
    model_name = _get_model_name(model)
    model_type = _get_model_type(model)
    
    if context:
        logger.error(f"‚ùå [{model_type}] [{context}] –ú–æ–¥–µ–ª—å: {model_name}, Latency: {latency:.2f}—Å, –û—à–∏–±–∫–∞: {error_msg}")
    else:
        logger.error(f"‚ùå [{model_type}] –ú–æ–¥–µ–ª—å: {model_name}, Latency: {latency:.2f}—Å, –û—à–∏–±–∫–∞: {error_msg}")


def log_api_success(model: str, latency: float, tokens_received: int = 0, context: str = ""):
    """
    –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ API –≤—ã–∑–æ–≤–∞ - –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py
    
    Args:
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        latency: –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        tokens_received: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        context: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    
    –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –≠—Ç–∞ –ª–æ–≥–∏–∫–∞ –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ –º–µ—Ç–æ–¥—É _log_api_success –∏–∑ claude_assistant.py (—Å—Ç—Ä–æ–∫–∏ 205-229)
    """
    # –¢–û–ß–ù–ê–Ø –ö–û–ü–ò–Ø –∏–∑ claude_assistant.py —Å—Ç—Ä–æ–∫–∏ 214-229
    log_api_call(model, True, latency, None)
    model_name = _get_model_name(model)
    model_type = _get_model_type(model)
    
    if tokens_received > 0:
        track_model_usage(model, True, tokens_received)
        if context:
            logger.info(f"‚úÖ [{model_type}] [{context}] –ú–æ–¥–µ–ª—å: {model_name}, –¢–æ–∫–µ–Ω–æ–≤: {tokens_received}, Latency: {latency:.2f}—Å")
        else:
            logger.info(f"‚úÖ [{model_type}] –ú–æ–¥–µ–ª—å: {model_name}, –¢–æ–∫–µ–Ω–æ–≤: {tokens_received}, Latency: {latency:.2f}—Å")
    else:
        track_model_usage(model, True, 0)
        if context:
            logger.info(f"‚úÖ [{model_type}] [{context}] –ú–æ–¥–µ–ª—å: {model_name}, Latency: {latency:.2f}—Å")
        else:
            logger.info(f"‚úÖ [{model_type}] –ú–æ–¥–µ–ª—å: {model_name}, Latency: {latency:.2f}—Å")










