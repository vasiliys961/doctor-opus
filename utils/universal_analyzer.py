"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: –∫–æ–Ω—Å–µ–Ω—Å—É—Å, –≤–∞–ª–∏–¥–∞—Ü–∏—é, –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞
"""
import streamlit as st
from typing import Dict, Any, Optional
from modules.medical_ai_analyzer import ImageType
from claude_assistant import OpenRouterAssistant
from services.consensus_engine import ConsensusEngine
from services.validation_pipeline import ValidationPipeline
from evaluators.scorecards import MedicalScorecard
from utils.gap_detector import DiagnosticGapDetector
from utils.notification_system import NotificationSystem
from utils.evidence_ranker import EvidenceRanker
from utils.specialist_detector import get_specialist_prompt, get_specialist_info
from storages.context_store import ContextStore
from services.model_router import ModelRouter
import numpy as np

class UniversalMedicalAnalyzer:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    
    def __init__(self):
        self.assistant = OpenRouterAssistant()
        self.consensus_engine = ConsensusEngine(self.assistant)
        self.validator = ValidationPipeline(self.assistant)
        self.scorecard = MedicalScorecard()
        self.gap_detector = DiagnosticGapDetector()
        self.notifier = NotificationSystem()
        self.evidence_ranker = EvidenceRanker()
        self.context_store = ContextStore()
        self.model_router = ModelRouter()
    
    def analyze_image(self, image_array: np.ndarray, image_type: ImageType, 
                     analysis_mode: str = "‚ö° –ë—ã—Å—Ç—Ä—ã–π (–æ–¥–Ω–∞ –º–æ–¥–µ–ª—å)",
                     metadata: Dict = None, patient_id: Optional[int] = None) -> Dict[str, Any]:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
        Args:
            image_array: –ú–∞—Å—Å–∏–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_type: –¢–∏–ø –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            analysis_mode: –†–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞
            metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞
            patient_id: ID –ø–∞—Ü–∏–µ–Ω—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        """
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞
        prompt = get_specialist_prompt(image_type)
        specialist_info = get_specialist_info(image_type)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        optimal_models = self.model_router.get_optimal_models(image_type)
        self.assistant.models = optimal_models + self.model_router.get_fallback_models()
        
        results = {
            'image_type': image_type,
            'specialist': specialist_info,
            'mode': analysis_mode,
            'result': None,
            'validation': None,
            'scorecard': None,
            'gaps': None,
            'evidence': None,
            'critical_findings': None,
            'consensus': None
        }
        
        if analysis_mode == "‚ö° –ë—ã—Å—Ç—Ä—ã–π (–æ–¥–Ω–∞ –º–æ–¥–µ–ª—å)":
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç–µ—Ä –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            result = self.assistant.send_vision_request(prompt, image_array, str(metadata or {}), use_router=True)
            results['result'] = result
            
        elif analysis_mode == "üéØ –ö–æ–Ω—Å–µ–Ω—Å—É—Å (–Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π)":
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Claude 4.5 –∏ Llama Vision –¥–ª—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ —Ä–µ–Ω—Ç–≥–µ–Ω–∞
            if image_type == ImageType.XRAY:
                xray_consensus_models = [
                    "anthropic/claude-sonnet-4.5",  # –û–±–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ Claude 4.5
                    "anthropic/claude-opus-4.5",    # –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
                    "meta-llama/llama-3.2-90b-vision-instruct"
                ]
                consensus_result = self.consensus_engine.analyze_with_consensus(
                    prompt, image_array, str(metadata or {}), custom_models=xray_consensus_models
                )
            else:
                consensus_result = self.consensus_engine.analyze_with_consensus(
                    prompt, image_array, str(metadata or {})
                )
            results['consensus'] = consensus_result
            results['result'] = consensus_result['consensus'].get('consensus_response', 
                consensus_result['consensus'].get('single_opinion', '–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞'))
            
        elif analysis_mode == "‚úÖ –° –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π":
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ä–æ—É—Ç–µ—Ä –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
            result = self.assistant.send_vision_request(prompt, image_array, str(metadata or {}), use_router=True)
            results['result'] = result
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ö–æ–¥–∫–∏
            critical_findings = self.notifier.check_critical_findings(result)
            results['critical_findings'] = critical_findings
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            validation_result = self.validator.validate_response(result, {'image_type': image_type.value})
            results['validation'] = validation_result
            
            # –û—Ü–µ–Ω–∫–∞
            scorecard_result = self.scorecard.evaluate_response(result, image_type)
            results['scorecard'] = scorecard_result
            
            # –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤
            gaps = self.gap_detector.detect_gaps(result, image_type)
            results['gaps'] = gaps
            
            # –û—Ü–µ–Ω–∫–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            evidence_ranking = self.evidence_ranker.rank_evidence(result)
            results['evidence'] = evidence_ranking
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞—Ü–∏–µ–Ω—Ç–∞
        if patient_id and results['result']:
            self.context_store.add_context(
                patient_id=patient_id,
                context_type='imaging',
                context_data={
                    'image_type': image_type.value,
                    'analysis': results['result'],
                    'specialist': specialist_info,
                    'mode': analysis_mode
                },
                source='ai_analysis'
            )
        
        return results
    
    def display_results(self, results: Dict[str, Any]):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –≤ Streamlit"""
        specialist_info = results['specialist']
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        st.markdown(f"### üß† –û—Ç–≤–µ—Ç –ò–ò ({specialist_info['role']}):")
        st.write(results['result'])
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞—Ö–æ–¥–∫–∏
        if results.get('critical_findings'):
            self.notifier.display_notifications(results['critical_findings'])
        
        # –ö–æ–Ω—Å–µ–Ω—Å—É—Å
        if results.get('consensus'):
            consensus_data = results['consensus']['consensus']
            if consensus_data.get('consensus_available'):
                st.metric("–£—Ä–æ–≤–µ–Ω—å —Å–æ–≥–ª–∞—Å–∏—è", f"{consensus_data.get('agreement_level', 0):.1%}")
                
                if consensus_data.get('discrepancies'):
                    st.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏:")
                    for disc in consensus_data['discrepancies']:
                        st.warning(f"‚Ä¢ {disc}")
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if results.get('scorecard'):
            scorecard_result = results['scorecard']
            st.markdown("### üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:")
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞", scorecard_result['grade'])
            with col2:
                st.metric("–ü–æ–ª–Ω–æ—Ç–∞", f"{scorecard_result['completeness']:.1%}")
            with col3:
                validation = results.get('validation', {})
                st.metric("–í–∞–ª–∏–¥–∞—Ü–∏—è", "‚úÖ –ü—Ä–æ–π–¥–µ–Ω–∞" if validation.get('is_valid', False) else "‚ùå –ù–µ –ø—Ä–æ–π–¥–µ–Ω–∞")
            with col4:
                gaps = results.get('gaps', {})
                st.metric("–ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å", f"{gaps.get('completeness_percentage', 0):.1f}%")
            
            # –û—Ç—á–µ—Ç –æ –ø—Ä–æ–±–µ–ª–∞—Ö
            if gaps and gaps.get('completeness_percentage', 100) < 80:
                gap_report = self.gap_detector.generate_gap_report(gaps)
                with st.expander("üìã –û—Ç—á–µ—Ç –æ –ø—Ä–æ–±–µ–ª–∞—Ö –≤ –æ—Ç–≤–µ—Ç–µ"):
                    st.text(gap_report)
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if scorecard_result.get('recommendations'):
                st.info("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:")
                for rec in scorecard_result['recommendations']:
                    st.write(f"‚Ä¢ {rec}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        if results.get('validation'):
            validation_result = results['validation']
            if validation_result.get('warnings'):
                st.warning("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
                for warning in validation_result['warnings']:
                    st.warning(f"‚Ä¢ {warning}")
        
        # –î–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if results.get('evidence'):
            evidence_ranking = results['evidence']
            evidence_report = self.evidence_ranker.generate_evidence_report(evidence_ranking)
            with st.expander("üìö –û—Ü–µ–Ω–∫–∞ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"):
                st.text(evidence_report)
