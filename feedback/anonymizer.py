"""
anonymizer.py - –£–¥–∞–ª–µ–Ω–∏–µ –ü–ò –∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤

–ó–∞–ø—É—Å–∫:
    python -c "from feedback.anonymizer import MedicalAnonymizer; from pathlib import Path; m = MedicalAnonymizer(); count = m.batch_process(Path('data/raw_feedback'), Path('data/anonymized_cases/cases_latest.jsonl')); print(f'‚úÖ {count} cases processed')"
"""

import json
import re
import uuid
from pathlib import Path
from typing import Dict
from datetime import datetime


class MedicalAnonymizer:
    """–£–¥–∞–ª—è–µ—Ç –ü–ò (–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ) –∏–∑ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤"""

    PII_PATTERNS = {
        "—Ñ–∏–æ_–ø–æ–ª–Ω–æ–µ": r"\b[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+\b",  # –§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ
        "—Ñ–∏–æ_—Ñ–∞–º–∏–ª–∏—è_–æ—Ç—á–µ—Å—Ç–≤–æ": r"\b[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+(?:–æ–≤–∏—á|–µ–≤–∏—á|–æ–≤–Ω–∞|–µ–≤–Ω–∞|–∏—á|–∏—á–Ω–∞)\b",  # –§–∞–º–∏–ª–∏—è –û—Ç—á–µ—Å—Ç–≤–æ
        "—Ñ–∏–æ_—Ñ–∞–º–∏–ª–∏—è_–∏–º—è": r"\b[–ê-–Ø–Å][–∞-—è—ë]+\s+[–ê-–Ø–Å][–∞-—è—ë]+\b",  # –§–∞–º–∏–ª–∏—è –ò–º—è (–¥–≤–∞ —Å–ª–æ–≤–∞ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π)
        "–¥–∞—Ç–∞_—Ä–æ–∂–¥–µ–Ω–∏—è": r"\b(0?[1-9]|[12]\d|3[01])[/\-\.](0?[1-9]|1[012])[/\-\.]\d{4}\b",
        "–º–µ–¥–∫–∞—Ä—Ç–∞": r"(?:‚Ññ|N|–Ω–æ–º–µ—Ä)?\s*[–ê-–Ø]{0,2}[-/]?\d{4,10}",
        "—Ç–µ–ª–µ—Ñ–æ–Ω": r"\+?\s*7\s*[-\(\)]?\d{3}\s*[-\)]?\d{3}\s*[-]?\d{2}\s*[-]?\d{2}",
        "email": r"\S+@\S+\.\S+",
        "–∞–¥—Ä–µ—Å": r"(?:—É–ª\.|—É–ª–∏—Ü–∞|–ø—Ä\.|–ø—Ä–æ—Å–ø–µ–∫—Ç|–ø–ª–æ—â\.|–ø–ª–æ—â–∞–¥—å)\s+[^,\n]+(?:,\s*–¥\.\s*\d+)?",
        "–ø–∞—Å–ø–æ—Ä—Ç": r"(?:–ø–∞—Å–ø–æ—Ä—Ç|–ø–∞—Å–ø\.)\s+[–ê-–Ø]{2}\s*\d{6}",
    }

    def __init__(self):
        self.stats = {"total": 0, "pii_found": 0}

    def anonymize(self, text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –ü–ò –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return ""
        
        anonymized = text
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –ø–æ—Ä—è–¥–∫–µ –æ—Ç –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –∫ –º–µ–Ω–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª–Ω–æ–µ –§–ò–û, –ø–æ—Ç–æ–º —Ñ–∞–º–∏–ª–∏—è+–æ—Ç—á–µ—Å—Ç–≤–æ, –ø–æ—Ç–æ–º —Ñ–∞–º–∏–ª–∏—è+–∏–º—è
        pattern_order = [
            "—Ñ–∏–æ_–ø–æ–ª–Ω–æ–µ",
            "—Ñ–∏–æ_—Ñ–∞–º–∏–ª–∏—è_–æ—Ç—á–µ—Å—Ç–≤–æ", 
            "—Ñ–∏–æ_—Ñ–∞–º–∏–ª–∏—è_–∏–º—è",
            "–¥–∞—Ç–∞_—Ä–æ–∂–¥–µ–Ω–∏—è",
            "–º–µ–¥–∫–∞—Ä—Ç–∞",
            "—Ç–µ–ª–µ—Ñ–æ–Ω",
            "email",
            "–∞–¥—Ä–µ—Å",
            "–ø–∞—Å–ø–æ—Ä—Ç"
        ]
        
        for category in pattern_order:
            if category in self.PII_PATTERNS:
                pattern = self.PII_PATTERNS[category]
                matches = list(re.finditer(pattern, anonymized, re.IGNORECASE))
                if matches:
                    self.stats["pii_found"] += len(matches)
                    anonymized = re.sub(pattern, f"[{category.upper()}]", anonymized, flags=re.IGNORECASE)
        
        return anonymized

    def process_feedback_file(self, feedback_file: Path) -> Dict:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç raw feedback –≤ anonymized case"""
        with open(feedback_file, "r", encoding="utf-8") as f:
            raw = json.load(f)

        return {
            "case_id": str(uuid.uuid4()),
            "created_at": datetime.now().isoformat(),
            "analysis_type": raw.get("analysis_type", "UNKNOWN"),
            "input": self.anonymize(raw.get("input_case", "")),
            "model_output": raw.get("model_output", ""),  # –û–±—ã—á–Ω–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ü–ò
            "correctness": raw.get("correctness", ""),
            "correct_answer": self.anonymize(raw.get("correct_answer", "")),
            "specialty": raw.get("specialty", ""),
            "comment": self.anonymize(raw.get("comment", "")),
            "anonymization_applied": True
        }

    def batch_process(self, raw_feedback_dir: Path, output_file: Path) -> int:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ feedback —Ñ–∞–π–ª—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ jsonl"""
        count = 0
        output_file.parent.mkdir(parents=True, exist_ok=True)

        if not raw_feedback_dir.exists():
            logger.warning(f"–ü–∞–ø–∫–∞ {raw_feedback_dir} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return 0

        with open(output_file, "a", encoding="utf-8") as out_f:
            for feedback_file in raw_feedback_dir.glob("*.json"):
                try:
                    case = self.process_feedback_file(feedback_file)
                    out_f.write(json.dumps(case, ensure_ascii=False) + "\n")
                    feedback_file.unlink()  # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
                    count += 1
                    self.stats["total"] += 1
                except Exception as e:
                    import logging
                    logging.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {feedback_file}: {e}")

        return count


if __name__ == "__main__":
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    anonymizer = MedicalAnonymizer()
    raw_dir = Path("data/raw_feedback")
    output_file = Path(f"data/anonymized_cases/cases_{datetime.now().strftime('%Y%m')}.jsonl")
    output_file.parent.mkdir(parents=True, exist_ok=True)

    count = anonymizer.batch_process(raw_dir, output_file)
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {count} –∫–µ–π—Å–æ–≤")
    print(f"üìä –£–¥–∞–ª–µ–Ω–æ –ü–ò: {anonymizer.stats['pii_found']} –≤—Ö–æ–∂–¥–µ–Ω–∏–π")
    print(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")


